{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 有监督学习-分类器与鸢尾花识别\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1 模块导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "print ('scikit-learn version:', sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 导入配套使用的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import IPython\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print ('IPython version:', IPython.__version__)\n",
    "print ('numpy version:', np.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.2  分类器问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2.1 鸢尾花（iris）的分类问题\n",
    "\n",
    "\n",
    "- 鸢尾花图片\n",
    "<img src=\"images/ch13/iris_flower.jpg\" width =300>\n",
    "\n",
    "\n",
    "- 考虑训练数据集（含 $n$ 条样本，或记录）\n",
    "    - 每条样本中，有多个数据，这些数据称之为属性（attribute）或特征（feature）\n",
    "    - 如果是有监督学习，还要有目标（target）属性\n",
    "\n",
    "\n",
    "- 数据集\n",
    "    - 在 dataset 子模块中\n",
    "    \n",
    "    \n",
    "<img src=\"images/ch13/flower.jpg\" width =300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2.2 数据的初期认识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "# 加载并返回 iris 数据集\n",
    "iris = datasets.load_iris() # 位于 root_path\\pkgs\\scikit-learn-0.19.2-py37heebcf9a_0\\Lib\\site-packages\\sklearn\\datasets\\data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.load_iris?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 普及一下datasets数据集\n",
    "#### sklearn 的数据集有好多个种\n",
    "\n",
    "- 自带的小数据集（packaged dataset）：sklearn.datasets.load_<name>  \n",
    "    - 数据集文件在sklearn安装目录下datasets\\data文件下\n",
    "- 可在线下载的数据集（Downloaded Dataset）：sklearn.datasets.fetch_<name>  \n",
    "    - 比较大的数据集，主要用于测试解决实际问题，支持在线下载\n",
    "    - 下载下来的数据，默认保存在~/scikit_learn_data文件夹下，可以通过设置环境变量SCIKIT_LEARN_DATA修改路径，datasets.get_data_home()获取下载路径\n",
    "- 计算机生成的数据集（Generated Dataset）：sklearn.datasets.make_<name>  \n",
    "    - 构造数据集\n",
    "- svmlight/libsvm格式的数据集：sklearn.datasets.load_svmlight_file(...)  \n",
    "- 从买了data.org在线下载获取的数据集：sklearn.datasets.fetch_mldata(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自带的小数据集有哪些？\n",
    "- datasets.load_boston #波士顿房价数据集  \n",
    "- datasets.load_breast_cancer #乳腺癌数据集  \n",
    "- datasets.load_diabetes #糖尿病数据集  \n",
    "- datasets.load_digits #手写体数字数据集  \n",
    "- datasets.load_files  \n",
    "- datasets.load_iris #鸢尾花数据集  \n",
    "- datasets.load_lfw_pairs  \n",
    "- datasets.load_lfw_people  \n",
    "- datasets.load_linnerud #体能训练数据集  \n",
    "- datasets.load_mlcomp  \n",
    "- datasets.load_sample_image  \n",
    "- datasets.load_sample_images  \n",
    "- datasets.load_svmlight_file  \n",
    "- datasets.load_svmlight_files  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 了解一下数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris.<TAB>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()   # 字典关键字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 认识几个不常见的单词 —— 关于 鸢尾花的特征属性\n",
    "    - sepal 萼片\n",
    "    - petal 花瓣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data  # 4 列依次是 萼片长度、萼片宽度、花瓣长度、花瓣宽度，单位：厘米"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 认识几个不常见的单词 —— 关于分类\n",
    "    - setosa 山鸢尾花\n",
    "    - versicolor 变色鸢尾花\n",
    "    - virginica 维吉尼亚鸢尾花"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 认识三种鸢尾花 —— 从左至右分别是：'setosa'、'versicolor'、'virginica'\n",
    "\n",
    "\n",
    "<img src=\"images/ch13/setosa_versicolor_virginica.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iris 数据集的介绍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.DESCR # DESCR 属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)  # 格式输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 鸢尾花数据集 (Iris Datasets) 小结\n",
    "\n",
    "\n",
    "- 基本信息\n",
    "    - 数据记录 —— 150 条\n",
    "    - 特征属性 —— 4 条（'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'）\n",
    "    - 目标属性 —— 1 条（calss）\n",
    "\n",
    "\n",
    "- 统计数据\n",
    "    - 表明花瓣的 长度和宽度 与 类别的相关性高，分别达到 0.9490 和 0.9565"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.3 数据准备 —— 用于训练与测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3.1 导入特征数据、目标数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 特征与目标 数据\n",
    "X_iris, y_iris = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看维度\n",
    "print(X_iris.shape, y_iris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出首行\n",
    "X_iris[0], y_iris[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3.2 选取部分特征\n",
    "\n",
    "\n",
    "- 提取属性 —— 前 2 个属性（萼片的长度、宽度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入分解数据模块\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取前 2 个属性\n",
    "X, y = X_iris[:,:2], y_iris #X, y = X_iris[:,:2], y_iris\n",
    "#X, y = X_iris[:,:], y_iris\n",
    "#here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "plt.plot(X[:,0],X[:,1],'.')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel(\"sepal width (cm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "plt.plot(X[:,0],X[:,1],'.')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel(\"sepal width (cm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,0],y,'.')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel(\"classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[:,1],y,'.')\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel(\"classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3.3 数据分解\n",
    "\n",
    "\n",
    "- 分解占比\n",
    "    - 训练集（占比 75%） training set\n",
    "    - 测试集（占比 25%） testing set\n",
    "\n",
    "\n",
    "- 调用函数 `train_test_split`\n",
    "\n",
    "\n",
    "- 语法\n",
    "```python\n",
    ">>> train_test_split(*arrays, **options)\n",
    "```\n",
    "\n",
    "\n",
    "- 功能 —— 分解数据集成 训练集 测试集 两部分\n",
    "\n",
    "\n",
    "- 参数\n",
    "    - \\*arrays —— 特征数据，目标数据\n",
    "    - \\*\\*options —— 关键字\n",
    "        - test_size 测试集的占比\n",
    "        - random_state 随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分解成训练集和测试集\n",
    "# 测试集随机取 25%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=53)\n",
    "print (X_train.shape, y_train.shape)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3.4  数据预处理\n",
    "\n",
    "\n",
    "- 标准化\n",
    "    - 每个数值减平均值 $mean$，然后除以标准差 $std$\n",
    "\n",
    "$$X = \\dfrac{X-mean}{std}$$\n",
    "\n",
    "\n",
    "- 目的\n",
    "    - 规范化数据\n",
    "    - 避免权重过大 \n",
    "\n",
    "\n",
    "- 标准化数据，满足\n",
    "    - 分布不变\n",
    "    - 0 均值\n",
    "    - 1 标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入标准化函数\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler介绍\n",
    "- 计算训练集的平均值和标准差，以便测试数据集使用相同的变换\n",
    "- 通过删除平均值和缩放到单位方差来标准化特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关于StandardScaler的例子\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler1 = StandardScaler()\n",
    "print(scaler1.fit(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler1.mean_) #输出平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = scaler1.transform(data)\n",
    "print(data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler1.transform([[2, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1.inverse_transform(data_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler介绍 - 方法  \n",
    "\n",
    "方法名称 | 方法作用  \n",
    "-  | -  \n",
    "`fit(X[, y])`\t | Compute the mean and std to be used for later scaling.<br>  计算用于以后缩放的mean和std\n",
    "`fit_transform(X[, y])`\t| Fit to data, then transform it. <br>适合数据，然后转换它\n",
    "`get_params([deep])`\t|Get parameters for this estimator.\n",
    "`inverse_transform(X[, copy])`\t|Scale back the data to the original representation\n",
    "`partial_fit(X[, y])`\t|Online computation of mean and std on X for later scaling.\n",
    "`set_params(**params)`\t|Set the parameters of this estimator.\n",
    "`transform(X[, y, copy])`\t|Perform standardization by centering and scaling <br>通过居中和缩放执行标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 言归正传"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征标准化\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3.5 可视化数据\n",
    "\n",
    "\n",
    "- 利用 Matplotlib.pyplot 子模块\n",
    "    - scatter 函数 （画散点图）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'greenyellow', 'blue']\n",
    "for i in range(len(colors)):\n",
    "    px = X_train[:, 0][y_train == i]\n",
    "    py = X_train[:, 1][y_train == i]\n",
    "    plt.scatter(px, py, c=colors[i])\n",
    "\n",
    "plt.legend(iris.target_names)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 观察发现\n",
    "    - 山鸢尾花 最容易区分\n",
    "    - 变色鸢尾花和维吉利亚鸢尾花混在一起"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.4 分类识别训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.4.1 基于随机梯度下降法的分类识别训练\n",
    "\n",
    "\n",
    "#### (1) 方法与分类器介绍\n",
    "\n",
    "\n",
    "- 随机梯度下降法 —— SGD, Stochastic Gradient Descent\n",
    "    - 一种寻找函数的局部最小值方法，比较著名\n",
    "    - 对于本例：算法通过最小化损失函数，<font color=\"red\">学习超平面的系数</font>\n",
    "<img src=\"images\\ch13\\lossfunc.png\" width = 400>\n",
    "\n",
    "- SGDClassifier 分类器\n",
    "    - 分类器（Classifier）的一种、基于随机梯度下降（Stochastic Gradient Descent）算法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建对象 线性模型分类器 linear model classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)  随机梯度下降法介绍\n",
    "#### 梯度\n",
    "- 在微积分里面，对多元函数的参数求∂偏导数，把求得的各个参数的偏导数以向量的形式写出来，就是梯度。\n",
    "- 比如函数f(x,y), 分别对x,y求偏导数，求得的梯度向量就是(∂f/∂x, ∂f/∂y)T,简称grad f(x,y)或者▽f(x,y)。\n",
    "- 对于在点(x0,y0)的具体梯度向量就是(∂f/∂x0, ∂f/∂y0)T.或者▽f(x0,y0)，如\n",
    "- 果是3个参数的向量梯度，就是(∂f/∂x, ∂f/∂y，∂f/∂z)T,以此类推。\n",
    "- 梯度向量求出来有什么意义呢？他的意义从几何意义上讲，就是函数变化增加最快的地方。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 梯度下降与梯度上升\n",
    "- 在机器学习算法中，在最小化损失函数时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。\n",
    "- 反过来，如果我们需要求解损失函数的最大值，这时就需要用梯度上升法来迭代了。\n",
    "\n",
    "- 梯度下降法和梯度上升法是可以互相转化的。比如我们需要求解损失函数f(θ)的最小值，这时我们需要用梯度下降法来迭代求解。\n",
    "- 但是实际上，我们可以反过来求解损失函数 -f(θ)的最大值，这时梯度上升法就派上用场了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 梯度下降法算法详解\n",
    "##### 梯度下降的直观解释\n",
    "- 比如我们在一座大山上的某处位置，由于我们不知道怎么下山，于是决定走一步算一步，也就是在每走到一个位置的时候，求解当前位置的梯度，沿着梯度的负方向，也就是当前最陡峭的位置向下走一步，然后继续求解当前位置梯度，向这一步所在位置沿着最陡峭最易下山的位置走一步。这样一步步的走下去，一直走到觉得我们已经到了山脚。当然这样走下去，有可能我们不能走到山脚，而是到了某一个局部的山峰低处。\n",
    "- 从上面的解释可以看出，梯度下降不一定能够找到全局的最优解，有可能是一个局部最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。\n",
    "<img src = 'images\\ch13\\ch13-01.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动画演示搜索过程\n",
    "<img src = 'images\\ch13\\ch13-02.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 分类器之成员函数 `fit`\n",
    "\n",
    "\n",
    "- 语法\n",
    "```python\n",
    ">>> clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "\n",
    "- 功能\n",
    "    - 基于训练数据训练模型\n",
    "    - 创建超平面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 拟合（训练）分类器\n",
    "clf.fit(X_train, y_train) # 注意参数设置警告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.4.2 训练成果 及 可视化展示\n",
    "\n",
    "\n",
    "- 学习效果\n",
    "    - 系数数组 coef_  $\\quad(c_1,c_2,\\cdots)$\n",
    "    - 截距数组 intercept_ $p$\n",
    "\n",
    "\n",
    "- 分界线方程 —— 超平面方程 $\\quad c_1f_1+c_2f_2 + \\cdots = p$\n",
    "     - $c_1,\\,c_2,\\,\\cdots$ 系数\n",
    "     - $f_1,\\,f_2,\\,\\cdots$ 特征值\n",
    "     - $p$ 右端项\n",
    "\n",
    "\n",
    "- 三次二元识别\n",
    "    - 将得到三组系数和截距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出 学习得到的系数\n",
    "print (clf.coef_)\n",
    "print (clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可视化展示\n",
    "    - 画出三条决策曲线\n",
    "    - 效果\n",
    "        - 类别 1 可以直线分开\n",
    "        - 类另 2 和 3 不能分开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X_train[:, 0].min() - .5, X_train[:, 0].max() + .5 # 找出最大最小值，用于画图\n",
    "y_min, y_max = X_train[:, 1].min() - .5, X_train[:, 1].max() + .5\n",
    "xs = np.arange(x_min,x_max,0.5) #xs数据（绘制直线用）\n",
    "fig, axes = plt.subplots(1,3)  #三个图\n",
    "fig.set_size_inches(10,6)  #设置图大小\n",
    "for i in [0,1,2]:  #按图循环\n",
    "    axes[i].set_aspect('equal')\n",
    "    axes[i].set_title('Class ' + str(i) + ' versus the rest')\n",
    "    axes[i].set_xlabel('Sepal length')\n",
    "    axes[i].set_ylabel('Sepal width')\n",
    "    axes[i].set_xlim(x_min, x_max)\n",
    "    axes[i].set_ylim(y_min, y_max)\n",
    "    plt.sca(axes[i])\n",
    "    for j in range(len(colors)):\n",
    "        px = X_train[:, 0][y_train == j]\n",
    "        py = X_train[:, 1][y_train == j]\n",
    "        plt.scatter(px, py, c=colors[j])\n",
    "    ys = (-clf.intercept_[i]-xs*clf.coef_[i,0])/clf.coef_[i,1]  #ys数据（绘制直线用）\n",
    "    plt.plot(xs,ys);#,hold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's how our classifier can predict the class of a certain instance, given its sepal length and width:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.4.3 预测未来新数据\n",
    "\n",
    "- 假设新数据（萼片的长度、宽度）为\n",
    "    - [4.7,3.1]\n",
    "\n",
    "\n",
    "- 操作过程\n",
    "    - 同样的数据预处理\n",
    "    - 三次二元分类识别\n",
    "    - 输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新数据\n",
    "new_data = [4.7, 3.1]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 感兴趣的同学，可以反复运行，检查预测结果是否变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform([new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理\n",
    "pre_process_data = scaler.transform([new_data])\n",
    "pre_process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类型预测 0-setosa, 1-versicolor, 2-virginica\n",
    "print (clf.predict(pre_process_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三个决策函数值筛选 —— 取最大值对应的类别\n",
    "print(clf.decision_function(pre_process_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.5 检验模型的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.5.1 导入模块 `metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.5.2 对比目标值 —— 人工结果\n",
    "\n",
    "\n",
    "- 调用函数\n",
    "```python\n",
    ">>> metrics.accuracy_score(y_train, y_train_pred)\n",
    "```\n",
    "\n",
    "\n",
    "- 参数\n",
    "    - y_train 人工结果值\n",
    "    - y_train_pred 预测值\n",
    "\n",
    "\n",
    "- 返回值\n",
    "    - score —— 分数介于 0 和 1 之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据模型得到的预测值\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# 与人工值比较，并输出得分\n",
    "train_score = metrics.accuracy_score(y_train, y_train_pred)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.5.3 用测试集来检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集也要标准化\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 预测\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 与人工值比较，并输出得分\n",
    "test_score = metrics.accuracy_score(y_test, y_pred)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.6  进一步分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.6.1 发现问题\n",
    "\n",
    "- 训练集的分数比测试集更好！\n",
    "    - $test\\_score < train\\_score$\n",
    "- 为什么？\n",
    "    - 合理而常见"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.6.2 试试更多的检验\n",
    "\n",
    "- 分类准确率分数是指所有分类正确的百分比。分类准确率这一衡量分类器的标准比较容易理解，但是它不能告诉你响应值的潜在分布，并且它也不能告诉你分类器犯错的类型。\n",
    "\n",
    "\n",
    "- Precision\n",
    "- Recall\n",
    "- F-score\n",
    "- 混淆矩阵 （the confusion matrix）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( metrics.classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "print (metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 准确率（正确率）=所有预测正确的样本/总的样本  （TP+TN）/总\n",
    "\n",
    "- 精确率=  将正类预测为正类 / 所有预测为正类 TP/（TP+FP）\n",
    "\n",
    "- 召回率 = 将正类预测为正类 / 所有正真的正类 TP/（TP+FN）\n",
    "\n",
    "- F值 = 精确率 * 召回率 * 2 / (正确率 + 召回率) （F 值即为精确率和召回率的调和平均值）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混淆矩阵也称误差矩阵\n",
    "<img src='images\\ch13\\ch13-04.jpg'><img src='images\\ch13\\ch13-03.jpg'>\n",
    "- 精确率_类别1=a/(a+d+g)\n",
    "- 召回率_类别1=a/(a+b+c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.6.3  K-折交叉检验分类器\n",
    "\n",
    "\n",
    "- 创建一个新的分类器\n",
    "    - 将数据集切分成 $k$ 部分\n",
    "    - 取其中 $k-1$ 块进行训练\n",
    "    - 取剩下的一块用来测试评估\n",
    "    - 进行 $k$ 次，取平均得分\n",
    "\n",
    "\n",
    "- pipeline （管道或管线），连接\n",
    "    - 标准化器\n",
    "    - 线性模型 —— 随机梯度下降分类器\n",
    "\n",
    "\n",
    "- 交叉检验精度 —— 对每一折"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images\\ch13\\ch13-05.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 流程更简洁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入函数等\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit_learn里的 pipeline\n",
    "- pipeline 实现了对全部步骤的流式化封装和管理，可以很方便地使参数集在新数据集上被重复使用。\n",
    "- pipeline 可以用于下面几处：\n",
    "    - 模块化 Feature Transform，只需写很少的代码就能将新的 Feature 更新到训练集中。  \n",
    "    - 自动化 Grid Search，只要预先设定好使用的 Model 和参数的候选，就能自动搜索并记录最佳的 Model。  \n",
    "    - 自动化 Ensemble Generation，每隔一段时间将现有最好的 K 个 Model 拿来做 Ensemble。  \n",
    "    - 要用 Pipeline 对训练集和测试集进行如下操作：\n",
    "        - 先用 StandardScaler 对数据集每一列做标准化处理，（是 transformer）\n",
    "        - 再用 PCA 将原始的 30 维度特征压缩的 2 维度，（是 transformer）\n",
    "        - 最后再用模型 LogisticRegression。（是 Estimator）\n",
    "        - 调用 Pipeline 时，输入由元组构成的列表，每个元组第一个值为变量名，元组第二个元素是 sklearn 中的 transformer 或 Estimator。\n",
    "        - 注意中间每一步是 transformer，即它们必须包含 fit 和 transform 方法，或者 fit_transform。\n",
    "        - 最后一步是一个 Estimator，即最后一步模型要有 fit 方法，可以没有 transform 方法。\n",
    "    - Pipeline对象接受二元tuple构成的list，每一个二元 tuple 中的第一个元素为 arbitrary identifier string，我们用以获取（access）Pipeline object 中的 individual elements，二元 tuple 中的第二个元素是 scikit-learn与之相适配的transformer 或者 estimator。  \n",
    "<img src='images\\ch13\\sklearn_pipeline.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建管线实现的复合估计器\n",
    "clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linear_model', SGDClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 k-折交叉验证迭代器，取 k=5\n",
    "# cv = KFold(X.shape[0], 5, shuffle=True, random_state=33)\n",
    "cv = KFold(5, shuffle=True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KFold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得分\n",
    "cross_scores = cross_val_score(clf, X, y, cv=cv)\n",
    "print(cross_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 交叉验证精度的均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "def mean_score(scores):\n",
    "    \"\"\"Print the empirical mean score and standard error of the mean.\"\"\"\n",
    "    return (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
    "        np.mean(scores), sem(scores))\n",
    "\n",
    "print(mean_score(cross_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.7 知识梳理\n",
    "\n",
    "- 主要流程\n",
    "    - 初识问题数据 —— 加载、观察、初步统计分析等\n",
    "    - 数据准备\n",
    "        - 导入特征、目标数据\n",
    "        - 选取重要特征 （重要环节）\n",
    "        - 数据分解\n",
    "        - 数据预处理\n",
    "        - 数据可视化\n",
    "    - 分类识别训练\n",
    "        - 选取方法与分类器\n",
    "        - 创建分类器对象\n",
    "        - 训练拟合 fit\n",
    "        - 检验训练成果\n",
    "        - 预测新数据\n",
    "    - 检验模型的效果\n",
    "        - 训练集检验\n",
    "        - 测试集检验\n",
    "    - 进一步分析\n",
    "        - 发现问题\n",
    "        - 改进方法\n",
    "            - 调整参数\n",
    "            - 选择其它方法\n",
    "            - 属性重新组合\n",
    "            - 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大家尝试用另外两个属性进行分类？\n",
    "# 并反馈平均得分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.7  其他类似例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# features column names\n",
    "column_names = ['Sample code number','Clump Thickness','Uniformity of Cell Size' ,'Uniformity of Cell Shape','Marginal Adhesion',\n",
    "'Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n",
    "\n",
    "#read data from csv file\n",
    "##data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data',names=column_names)\n",
    "data = pd.read_csv('data/breast-cancer-wisconsin.data',names=column_names)\n",
    "#data = pd.read_csv('data/breast-cancer-wisconsin.data',names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images\\ch13\\ch13-06.jpg' width =500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "#replace all ? with standard missing value\n",
    "\n",
    "data = data.replace(to_replace='?',value=np.nan)\n",
    "\n",
    "#drop all data rows which have any missing feature\n",
    "data=data.dropna(how='any')\n",
    "\n",
    "# data.to_csv('data\\text.csv')# save data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes:you should use cross_valiation instead of model_valiation in python 2.7\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split #DeprecationWarning\n",
    "\n",
    "from sklearn.model_selection import train_test_split #use train_test_split module of sklearn.model_valiation to split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take 25 percent of data randomly for testing,and others for training\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data[column_names[1:10]],data[column_names[10]],test_size=0.25,random_state=33)\n",
    "\n",
    "#check the numbers and category distribution of the test samples\n",
    "# print(y_train.value_counts())\n",
    "# print(y_test.value_counts())\n",
    "\n",
    "#import relative package\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#standardizing data in train set and test set\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "#sgdcclassifier model\n",
    "#sgdc=SGDClassifier() #DeprecationWarning\n",
    "\n",
    "sgdc=SGDClassifier(max_iter=5,tol=None)\n",
    "\n",
    "#call fit function to trainning arguments ofmodel\n",
    "sgdc.fit(X_train,y_train)\n",
    "\n",
    "sgdc_y_predict=sgdc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance analysis\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#get accuracy by the score function in SGD classifier\n",
    "print('Accuracy of SGD Classifier:',sgdc.score(X_test,y_test))\n",
    "\n",
    "#get  precision ,recall and f1-score from classification_report module\n",
    "print(classification_report(y_test,sgdc_y_predict,target_names=['Benign','Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入函数等\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建管线实现的复合估计器\n",
    "clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linear_model', SGDClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[column_names[1:10]], data[column_names[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 k-折交叉验证迭代器，取 k=5\n",
    "#cv = KFold(X.shape[0], 5, shuffle=True, random_state=33)\n",
    "cv = KFold(5, shuffle=True, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得分\n",
    "cross_scores = cross_val_score(clf, X, y, cv=cv)  #检查数据是否有缺失？\n",
    "print(cross_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "def mean_score(scores):\n",
    "    \"\"\"Print the empirical mean score and standard error of the mean.\"\"\"\n",
    "    return (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
    "        np.mean(scores), sem(scores))\n",
    "\n",
    "print(mean_score(cross_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第13讲 结束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 葡萄酒分类！\n",
    "<img src='images\\ch13\\ch13-08.png' width =500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习！\n",
    "#https://archive.ics.uci.edu/ml/datasets/Wine\n",
    "column_names  = [\"class\", \"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \"Magnesium\", \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \"Proanthocyanins\", \"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\", \"Proline\"]\n",
    "#data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',names=column_names)\n",
    "data = pd.read_csv('data/wine.data',names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images\\ch13\\ch13-07.png' width =500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请用本堂课的知识，建立一个分类器\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
