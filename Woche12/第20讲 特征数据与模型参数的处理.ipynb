{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 特征数据与模型参数的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.1 机器学习可能面临的若干问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1.1 数据的问题\n",
    "\n",
    "\n",
    "- 数据未必是现成的 `属性/目标` 配对\n",
    "    - 可能更复杂(不同构)\n",
    "        - 图片\n",
    "        - 缺陷\n",
    "    - 也可能根本不成(数据)结构\n",
    "        - 文本\n",
    "        - 音视频\n",
    "\n",
    "\n",
    "- 基本技能 —— `特征提取(Feature Extraction)`\n",
    "    - 提取（提炼） `scikit-learn` 能用的特征\n",
    "    - ......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1.2 特征的问题\n",
    "\n",
    "\n",
    "- 初始数据集所包含的\n",
    "    - 未必都是有用的特征\n",
    "    - 甚至有些极低信息量(无用、无关、冗余......)的数据特征\n",
    "\n",
    "\n",
    "- 重要技能 —— `特征选择(Feature Selection)`\n",
    "    - 选择最恰当的特征集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1.3 参数的问题\n",
    "\n",
    "\n",
    "- 前述 `有/无 监督学习` 表明\n",
    "    - 机器学习算法需要 `设置/调整 参数`\n",
    "\n",
    "\n",
    "- 关键技能 —— `模型选择(Model Selection)`\n",
    "    - 找到最理想的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.2 特征提取 (Feature Extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2.1 机器学习流程与数据准备困难\n",
    "\n",
    "\n",
    "- 机器学习的任务流程\n",
    "    - 数据准备\n",
    "        - 多样本\n",
    "        - 多特征 + (多)目标\n",
    "        - 数据预处理\n",
    "    - 通过训练数据的学习，获得经验\n",
    "    - 对于将来未知的样本特征数据，预测其目标值\n",
    "\n",
    "\n",
    "- 数据准备的困难\n",
    "    - 源数据可能不是适宜的数据格式\n",
    "        - 20 新闻组\n",
    "        - 非统一格式照片\n",
    "        - 其它格式\n",
    "    - 有必要\n",
    "        - 提取潜在的有用特征\n",
    "        - 并将其转换成可用的格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2.2 特征提取的实质\n",
    "\n",
    "\n",
    "- 提取潜在的有用特征称为\n",
    "    - 特征提取 或 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 步骤\n",
    "\n",
    "\n",
    "- 处理源数据\n",
    "    - 整理、归类、存档等\n",
    "\n",
    "\n",
    "- 提取样本数据\n",
    "    - 通常的格式：特征值/目标值\n",
    "    - 值的类型：整数、浮点数、字符串、分类值等\n",
    "        - 一律要转换成数值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 方法 —— 无定规，（强）依赖于数据的表现形式\n",
    "\n",
    "\n",
    "- 贴标签(特征或目标) —— 如 `Titanic` 号生还预测、鸢尾花分类等\n",
    "- 提取数据(特征或目标) —— 如 `20` 新闻组 `tfidf` 等\n",
    "- 人工生成(特征或目标) —— 如头像识别判断是否戴眼镜\n",
    "- 使用各种工具\n",
    "- 其它 ......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2.3 转换特征\n",
    "\n",
    "\n",
    "- Scikit-Learn 对样本数据的要求\n",
    "    - 数据集 —— 样本数据组成的集合\n",
    "    - 样本 = 多个特征值 + 目标值\n",
    "    - 值：必须是浮点或整数值\n",
    "\n",
    "\n",
    "- 现状\n",
    "    - 得到这样的数据并不总是轻松\n",
    "\n",
    "\n",
    "- 办法\n",
    "    - 专门编写转换程序\n",
    "    - 利用软件模块，如 `pandas` 等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2.4 回顾 Titanic 乘客生还预测问题\n",
    "\n",
    "\n",
    "- 模块准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import IPython\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "\n",
    "print ('IPython version:', IPython.__version__)\n",
    "print ('numpy version:', np.__version__)\n",
    "print ('matplotlib version:', matplotlib.__version__)\n",
    "\n",
    "print ('scikit-learn version:', sk.__version__)\n",
    "print ('pandas version:', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('data/titanic.csv')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 观察数据\n",
    "    - 共有 1313 行、11 列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据帧的每一列\n",
    "    - 对应一个特征(或目标)\n",
    "    - 有些是值\n",
    "    - 有些是分类值 —— 如 `embarked` 列的 `Southampton`、`Cherbourg` 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()[['pclass', 'survived', 'age', 'embarked', 'boat', 'sex']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 遇到困难\n",
    "    - `scikit-learn` 希望的特征是实数值\n",
    "    - 需要做转换\n",
    "\n",
    "\n",
    "- 曾经用过工具转换数据\n",
    "    - `LabelEncoder`\n",
    "    - `OneHotEncoder`\n",
    "\n",
    "\n",
    "- 新的转换工具\n",
    "    - `DictVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2.5 转换特征工具 —— `DictVectorizer`\n",
    "\n",
    "\n",
    "- 字典向量化器 —— 特征提取工具\n",
    "- 利用原特征名称，组合新特征\n",
    "- 采用 `0/1` 方式进行量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 导入 feature_extraction 模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 定义函数\n",
    "\n",
    "\n",
    "- 函数 `one_hot_dataframe` 调用方式\n",
    "\n",
    "```python\n",
    ">>> new_data_frame, vec_data_frame = one_hot_dataframe(data, cols, replace=False)\n",
    "```\n",
    "\n",
    "\n",
    "- 功能 —— 转换特征成新数据帧\n",
    "\n",
    "\n",
    "- 参数\n",
    "    - `data` 数据帧\n",
    "    - `cols` 指定若干列\n",
    "    - `replace` 是否替换 `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_dataframe(data, cols, replace=False):\n",
    "    \"\"\" \n",
    "    取数据帧和有待解码的若干列\n",
    "    返回：数据data、向量化数据，以及拟合的向量化器\n",
    "    \"\"\"\n",
    "    vec = feature_extraction.DictVectorizer()                   # 生成 DictVectorizer 对象\n",
    "    mkdict = lambda row: dict((col, row[col]) for col in cols) # 映射：列标识 -> 行的对应元素\n",
    "    \n",
    "    vecData = pd.DataFrame(vec.fit_transform(data[cols].apply(mkdict, axis=1)).toarray()) # 重构数据帧\n",
    "    vecData.columns = vec.get_feature_names()\n",
    "    vecData.index = data.index\n",
    "    \n",
    "    if replace is True:\n",
    "        data = data.drop(cols, axis=1)\n",
    "        data = data.join(vecData)\n",
    "\n",
    "    return (data, vecData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 转换 `titanic` 数据帧的三列 `pclass`、`embarked` 和 `sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic, titanic_n = one_hot_dataframe(titanic, ['pclass', 'embarked', 'sex'], replace=True)\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 观察新数据帧\n",
    "\n",
    "\n",
    "- 由 `pclass` 特征 生出 三个新特征\n",
    "    - `pclass=1st`\n",
    "    - `pclass=2nd`\n",
    "    - `pclass=3rd`\n",
    "- 由 `embarked` 特征 生出 三个新特征\n",
    "    - `embarked=Cherbourg`\n",
    "    - `embarked=Queenstown`\n",
    "    - `embarked=Southampton`\n",
    "- 由 `sex` 特征 生出 两个新特征\n",
    "    - `sex=female`\n",
    "    - `sex=male`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 特征的存与灭\n",
    "\n",
    "\n",
    "- 失踪的特征\n",
    "    - `embarked` 还存在\n",
    "    - `pclass` 和 `sex` 不见了\n",
    "\n",
    "\n",
    "- 原因 —— 原 `embarked` 特征中有丢失的值 `NaN`\n",
    "\n",
    "\n",
    "- 注意\n",
    "    - 原 `embarked` 值存在时，新 `embarked` 值为 0\n",
    "    - 原 `embarked` 值为 `NaN` 时，新 `embarked` 值仍为 `NaN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) 小心遭遇魔咒 —— 再解码一组特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic, titanic_n = one_hot_dataframe(titanic, ['home.dest', 'room', 'ticket', 'boat'], replace=True)\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 解码引起特征数急剧增长，达到 581 个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (7) 处理丢失的值\n",
    "\n",
    "\n",
    "- 许多算法都不能接受 `NaN`\n",
    "- 可以使用 `Pandas` 的 `fillna` 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算平均年龄\n",
    "mean = titanic['age'].mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将缺失的年龄都用平均年龄来替代\n",
    "titanic['age'].fillna(mean, inplace=True)\n",
    "titanic.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 现在，所有丢失的值都得到处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2.6 对 `Titanic` 数据进行训练、测试..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 数据拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "titanic_target = titanic['survived']\n",
    "titanic_data = titanic.drop(['name', 'row.names', 'survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(titanic_data, titanic_target, test_size=0.25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 采用决策树\n",
    "\n",
    "\n",
    "- 训练\n",
    "- 测试\n",
    "- 评价 —— 得分 = 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "dt = dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "print (\"精度得分:{0:.3f}\".format(metrics.accuracy_score(y_test, y_pred)), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.3 特征选择 (Feature Selection)\n",
    "\n",
    "\n",
    "- 注意到 —— 前述决策树算法，用了全部的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.3.1 问题 —— 应该使用多少特征？\n",
    "\n",
    "\n",
    "- 两种倾向\n",
    "    - 使用全部信息，当然是多多益善\n",
    "    - 限制 算法使用的特征数量\n",
    "\n",
    "\n",
    "- 限制特征数量的原因\n",
    "    - 原因之一 —— 关注相关性\n",
    "        - 某些算法（包括决策树），无关的特征可能碰巧产生与目标的相关性，这未必正确，但易导致过拟合\n",
    "        - 有些特征有可能高度相关，可能引起算法上的冗余\n",
    "    - 原因之二 —— 考虑计算量\n",
    "        - 过多的特征易引起大计算量，尤其是对于大数据问题\n",
    "        - 与维度魔咒类似的问题，难于分析如下问题\n",
    "        $$过多特征 + 过多样本$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.3.2 特征选择 —— 通过算法寻找最佳特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) `Titanic` 特征如何变得臃肿？\n",
    "\n",
    "- 增加到 581 个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 要紧吗？\n",
    "\n",
    "\n",
    "- 或许这里还不至于引起问题\n",
    "- 但必须尽量避免 —— 可能出现的特征数急剧膨胀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 决策树算法 —— 要避免过拟合\n",
    "\n",
    "\n",
    "- 当分支基于很小的样本数时，对于未知数据的预测能力可能显著降低\n",
    "- 决策树的解决办法\n",
    "    -  调参：最大层数、叶结点的最小样本数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 本节的解决办法\n",
    "\n",
    "\n",
    "- 特征选择\n",
    "    - 限制特征数 —— 如何限制？\n",
    "    - 选择最有效的那些特征 —— 如何选择？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 特征选择函数\n",
    "\n",
    "- 语法\n",
    "\n",
    "```python\n",
    ">>> feature_selection.SelectPercentile(score_func=<function f_classif>, percentile=10)\n",
    "```\n",
    "\n",
    "- 功能 —— 根据最高得分的分位数选择特征\n",
    "\n",
    "\n",
    "- 参数\n",
    "    - `score_func` 可调用函数，两个参数 `X` 和 `y`，返回 得分数组 `(scores, pvalues)`\n",
    "    - `percentile` 拟保留的特征百分比，缺省值 10\n",
    "\n",
    "\n",
    "- 属性\n",
    "    - `scores_` 特征得分\n",
    "    - `pvalues_` 特征得分 `p` 值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=20)\n",
    "X_train_fs = fs.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection.chi2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看特征的得分\n",
    "fs.scores_, fs.scores_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_train_fs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 选取了 115 个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train_fs, y_train) # 训练特征树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "\n",
    "X_test_fs = fs.transform(X_test)   # 选取特征\n",
    "y_pred_fs = dt.predict(X_test_fs)  # 预测所选取的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估略高于前\n",
    "print (\"精度得分:{0:.3f}\".format(metrics.accuracy_score(y_test, y_pred_fs)),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "percentiles = range(1, 100, 5) # [1, 6, 11, 16, 21, ...... ]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for percentile in percentiles:\n",
    "    fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=percentile)\n",
    "    X_train_fs = fs.fit_transform(X_train, y_train)\n",
    "    scores = model_selection.cross_val_score(dt, X_train_fs, y_train, cv=5)\n",
    "\n",
    "    results = np.append(results, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, r in zip(percentiles,results):\n",
    "    print(\"{0:2},  {1}\".format(p, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_percentil = np.where(results == results.max())[0]\n",
    "#print (\"Optimal percentil:{0}\".format(percentiles[optimal_percentil]), \"\\n\")\n",
    "print (\"最优百分位数:{0}\".format(percentiles[optimal_percentil[0]]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (7) 特征数 - 交叉验证评分 图\n",
    "\n",
    "\n",
    "- 特征百分位数取 6 时，评分最高 0.879 左右\n",
    "- 特征百分位数取 6 以上时，稳定评分在 0.86 左右"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.xlabel(\"Percentile selected\")\n",
    "plt.ylabel(\"Cross validation accuracy)\")\n",
    "plt.plot(np.array(percentiles), results)\n",
    "\n",
    "print (\"平均得分:\\n\",results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (8) 最佳表现 —— 相比最初 0.83 左右的得分，有轻微的改善\n",
    "\n",
    "- 分位数 = 6\n",
    "- 特征数 = 34\n",
    "- 评分 = 0.857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_percentil = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile=optimal_percentil)\n",
    "\n",
    "X_train_fs = fs.fit_transform(X_train, y_train)  # 特征选取\n",
    "dt.fit(X_train_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fs = fs.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs.shape, X_test_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fs = dt.predict(X_test_fs)\n",
    "\n",
    "print (\"精度得分:{0:.3f}\".format(metrics.accuracy_score(y_test, y_pred_fs)), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.3.3 进一步改善\n",
    "\n",
    "\n",
    "- 调整参数   `criterion` 选择不同的决策树准则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 采用熵准则 —— `criterion='entropy'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "scores = model_selection.cross_val_score(dt, X_train_fs, y_train, cv=5)\n",
    "print (\"Entropy criterion accuracy on cv: {0:.3f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 采用基尼准则 —— `criterion='gini'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier(criterion='gini')\n",
    "scores = model_selection.cross_val_score(dt, X_train_fs, y_train, cv=5)\n",
    "print (\"Gini criterion accuracy on cv: {0:.3f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 作用于测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train_fs, y_train)\n",
    "\n",
    "X_test_fs = fs.transform(X_test)\n",
    "y_pred_fs = dt.predict(X_test_fs)\n",
    "\n",
    "print (\"精度得分: {0:.3f}\".format(metrics.accuracy_score(y_test, y_pred_fs)),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 讨论\n",
    "\n",
    "\n",
    "- 以前发生过\n",
    "    - 测试集的表现不如交叉验证的表现\n",
    "    - 这是正常现象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.4 模型选择(Model Selection)\n",
    "\n",
    "\n",
    "- 前 2 节的工作至关重要\n",
    "    - 特征提取 —— 预处理数据\n",
    "    - 特征选择 —— 选出最理想的特征组\n",
    "\n",
    "\n",
    "- 本节讨论另一个重要步骤 —— 选择算法参数 亦称 超参数(`hyperparameters`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.4.1 回顾基于朴素贝叶斯方法的文本分类问题\n",
    "\n",
    "\n",
    "- 20 新闻组\n",
    "- TF-IDF\n",
    "- 基于多项式的朴素贝叶斯算法 —— `Multinomial Naïve Bayes Algorithm`\n",
    "    - `MultinomialNB` 对象\n",
    "- 对信息短文进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) `MultinomialNB` 对象的重要参数\n",
    "\n",
    "- `alpha` —— 用来调节光滑性的参数\n",
    "    - 取缺省值 1.0 时，得分 0.89\n",
    "    - 改进到取 0.01 时，得分 0.92\n",
    "\n",
    "\n",
    "- 显然，参数 `alpha` 对分类效果影响显著\n",
    "\n",
    "\n",
    "- 问题 —— `alpha=0.01` 是最佳参数吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 重新加载 `fetch_20newsgroups` 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups(subset='all')\n",
    "n_samples = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = news.data[:n_samples]\n",
    "y_train = news.target[:n_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 导入相关类\n",
    "\n",
    "\n",
    "- MultinomialNB\n",
    "- Pipeline\n",
    "- TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 设置 `stop_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words():\n",
    "    result = set()\n",
    "    for line in open('data/stopwords_en.txt', 'r').readlines():\n",
    "        result.add(line.strip())\n",
    "    return result\n",
    "\n",
    "stop_words = get_stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 创建分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",\n",
    "    )),\n",
    "    ('nb', MultinomialNB(alpha=0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) 交叉验证、 K-折"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from scipy.stats import sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(clf, X, y, K):\n",
    "    cv = KFold(K, shuffle=True, random_state=0)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    print (scores)\n",
    "    print ((\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cross_validation(clf, X_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.4.2 参数优化分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 分析参数序列 —— 得到最优结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义函数\n",
    "\n",
    "```python\n",
    ">>> calc_params(X, y, clf, param_values, param_name, K)\n",
    "```\n",
    "\n",
    "\n",
    "- 功能 —— 实现对参数序列的计算、绘效果图\n",
    "\n",
    "\n",
    "- 参数说明 —— 略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_params(X, y, clf, param_values, param_name, K):\n",
    "    train_scores = np.zeros(len(param_values))\n",
    "    test_scores = np.zeros(len(param_values))\n",
    "\n",
    "    for i, param_value in enumerate(param_values):\n",
    "        print (param_name, ' = ', param_value)\n",
    "        clf.set_params(**{param_name:param_value})\n",
    "        k_train_scores = np.zeros(K)\n",
    "        k_test_scores = np.zeros(K)\n",
    "        #cv = KFold(n_samples, K, shuffle=True, random_state=0)\n",
    "        cv = KFold(K, shuffle=True, random_state=0)\n",
    "\n",
    "        #for j, (train, test) in enumerate(cv):\n",
    "        for j, (train, test) in enumerate(cv.split(X)):\n",
    "            clf.fit([X[k] for k in train], y[train])\n",
    "            k_train_scores[j] = clf.score([X[k] for k in train], y[train])\n",
    "            k_test_scores[j] = clf.score([X[k] for k in test],y[test])\n",
    "\n",
    "        train_scores[i] = np.mean(k_train_scores)\n",
    "        test_scores[i] = np.mean(k_test_scores)\n",
    "\n",
    "    plt.semilogx(param_values, train_scores, alpha=0.4, lw=2, c='b', label=\"Train\")\n",
    "    plt.semilogx(param_values, test_scores, alpha=0.4, lw=2, c='g', label=\"Test\")\n",
    "\n",
    "    plt.xlabel(\"Alpha values\")\n",
    "    plt.ylabel(\"Mean cross-validation accuracy\")\n",
    "    \n",
    "    plt.legend()\n",
    "\n",
    "    return train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 参数序列 `alphas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-7, 0, 8)\n",
    "print (alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 调用函数、K-折\n",
    "\n",
    "```python\n",
    ">>> calc_params(X_train, y_train, clf, alphas, 'nb__alpha', 3)`\n",
    "```\n",
    "\n",
    "- 注意 $K=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores, test_scores = calc_params(X_train, y_train, clf, alphas, 'nb__alpha', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 分析\n",
    "\n",
    "\n",
    "- 训练效果总是好于测试效果\n",
    "- 最佳测试效果对应的参数取值 $\\alpha \\in (10^{-2}, 10^{-1})$\n",
    "\n",
    "\n",
    "- 过拟合区间 $\\alpha \\lt 10^{-2}$\n",
    "    - 训练精度高，但测试精度过低\n",
    "\n",
    "\n",
    "- 欠拟合区间 $\\alpha \\gt 10^{-1}$\n",
    "    - 训练精度过低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.4.3 采用支持向量机分类器 `SVC`\n",
    "\n",
    "\n",
    "- 另一参数进行优化\n",
    "    - `gamma`\n",
    "    \n",
    "\n",
    "- 参数说明\n",
    "    - `gamma` 是选择 `RBF` 函数作为 `kernel` 后，该函数自带的一个参数\n",
    "    - 决定了数据映射到新的特征空间后的分布\n",
    "        - `gamma` 越大，支持向量越少\n",
    "        - `gamma` 值越小，支持向量越多\n",
    "    - 支持向量的个数影响训练与预测的速度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 创建分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",\n",
    "    )),\n",
    "    ('svc', SVC()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 参数序列 `gammas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = np.logspace(-2, 1, 4)\n",
    "gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores, test_scores = calc_params(X_train, y_train, clf, gammas,'svc__gamma', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas, train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 结果分析\n",
    "\n",
    "\n",
    "- $\\gamma \\lt 1$ 时，欠拟合分析\n",
    "- $\\gamma \\gt 1$ 时，过拟合分析\n",
    "\n",
    "\n",
    "- $\\gamma = 1$ 时，效果最优\n",
    "    - 训练得分 0.999\n",
    "    - 测试得分 0.746"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 进一步思考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建 `SVC` 对象的语法\n",
    "\n",
    "```python\n",
    ">>> SVC(C=1.0, kernel='rbf', degree=3,\n",
    "        gamma='auto', coef0=0.0, shrinking=True,\n",
    "        probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False,\n",
    "        max_iter=-1, decision_function_shape='ovr', random_state=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `SVC` 对象还有其它参数\n",
    "    - `C`\n",
    "    - `kernel`\n",
    "    - 等\n",
    "\n",
    "\n",
    "- 如果考虑更多的参数组合\n",
    "    - 将产生新的复杂问题\n",
    "    \n",
    "    \n",
    "- 怎么办？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.5 参数搜索\n",
    "\n",
    "\n",
    "- 网格搜索\n",
    "- 平行网格搜索（略）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5.1 子模块 `model_selection` 中导入 `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5.2 参数组合域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'svc__gamma': np.logspace(-2, 1, 4),\n",
    "    'svc__C': np.logspace(-1, 1, 3),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5.3 创建分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",\n",
    "    )),\n",
    "    ('svc', SVC()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5.4 创建 `GridSearchCV` 对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf, parameters, verbose=2, refit=False, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5.5 训练、评价、K-折"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time _ = gs.fit(X_train, y_train)\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5.6 小结\n",
    "\n",
    "\n",
    "- 网格搜索得到更好的参数组合\n",
    "    - `C=10`\n",
    "    - `gamma=0.10`\n",
    "\n",
    "\n",
    "- 相应的测试得分\n",
    "    - 得分 0.827\n",
    "\n",
    "\n",
    "- 对比前面的分析 —— 仅调整参数 `gamma`(保持 `C` 为 1)\n",
    "    - 得分 0.746\n",
    "    \n",
    "\n",
    "- 更一般地考虑\n",
    "    - 调整更多的 `TfidfVectorizer` 参数\n",
    "    - 更加复杂\n",
    "    \n",
    "\n",
    "- 时间因素\n",
    "    - 上面的分析用时 4+ 分钟(可能有微小变化)\n",
    "    - 如果考虑更多的参数呢？\n",
    "    - 时间呈几何级数上升......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.5.7 有待进一步思考的问题\n",
    "\n",
    "\n",
    "- 参数优化该如何做？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第20讲 结束"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
